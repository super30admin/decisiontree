{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ2q8SX_HCHz"
      },
      "source": [
        "# Decision Trees — Student Lab\n",
        "\n",
        "We start using **sklearn** in Week 4, but you’ll still implement core pieces from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZA8FDYOZHCH3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def check(name: str, cond: bool):\n",
        "    if not cond:\n",
        "        raise AssertionError(f'Failed: {name}')\n",
        "    print(f'OK: {name}')\n",
        "\n",
        "rng = np.random.default_rng(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3qJJLzdHCH4"
      },
      "source": [
        "## Section 0 — Synthetic dataset\n",
        "We’ll create a non-linear boundary dataset to show how trees fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nbg9nR8nHCH4",
        "outputId": "e286486f-d1b6-43b5-f754-4ba5ceb34f5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: shapes\n"
          ]
        }
      ],
      "source": [
        "def make_nonlinear(n=400):\n",
        "    X = rng.uniform(-2, 2, size=(n, 2))\n",
        "    # circle boundary\n",
        "    r = np.sqrt(X[:,0]**2 + X[:,1]**2)\n",
        "    y = (r < 1.0).astype(int)\n",
        "    # add noise\n",
        "    flip = rng.random(n) < 0.05\n",
        "    y[flip] = 1 - y[flip]\n",
        "    return X, y\n",
        "\n",
        "X, y = make_nonlinear()\n",
        "n = X.shape[0]\n",
        "idx = rng.permutation(n)\n",
        "tr = idx[: int(0.7*n)]\n",
        "va = idx[int(0.7*n):]\n",
        "Xtr, ytr = X[tr], y[tr]\n",
        "Xva, yva = X[va], y[va]\n",
        "check('shapes', Xtr.shape[0]==ytr.shape[0] and Xva.shape[0]==yva.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18f66Z1AHCH4"
      },
      "source": [
        "## Section 1 — Impurity\n",
        "\n",
        "### Task 1.1: Gini impurity\n",
        "\n",
        "# TODO: implement gini(y)\n",
        "# HINT: p_k = count_k / n; gini = 1 - sum(p_k^2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ORmirCPKHCH4",
        "outputId": "7b8edca8-ac30-4b1a-d68f-9e5c518ce115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: gini_pure0\n",
            "OK: gini_half\n"
          ]
        }
      ],
      "source": [
        "def gini(y):\n",
        "    # TODO\n",
        "    if y.shape[0] == 0 :\n",
        "      return 0.0\n",
        "    p1 = y.mean()\n",
        "    p0 = 1-p1\n",
        "    return 1 - (p0*p0 + p1*p1)\n",
        "\n",
        "check('gini_pure0', abs(gini(np.zeros(10, dtype=int))) < 1e-12)\n",
        "check('gini_half', abs(gini(np.array([0,1]*5)) - 0.5) < 1e-12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzT0muLRHCH4"
      },
      "source": [
        "### Task 1.2: Entropy\n",
        "\n",
        "# TODO: implement entropy(y)\n",
        "# HINT: entropy = -sum p log2 p (use eps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yieBAwyCHCH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0b36b0-3569-46ad-fd92-89584ac47f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: entropy_pure0\n",
            "OK: entropy_half\n"
          ]
        }
      ],
      "source": [
        "def entropy(y):\n",
        "    if y.shape[0] == 0:\n",
        "      return 0.0\n",
        "    p1 = y.mean()\n",
        "    p0 = 1-p1\n",
        "    eps = 1e-15\n",
        "    return float(-(p1 * np.log2(p1+eps) + p0 * np.log2(p0+eps)))\n",
        "\n",
        "check('entropy_pure0', abs(entropy(np.zeros(10, dtype=int))) < 1e-12)\n",
        "check('entropy_half', abs(entropy(np.array([0,1]*5))) < 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l_33gX9HCH5"
      },
      "source": [
        "## Section 2 — Best split (decision stump)\n",
        "\n",
        "### Task 2.1: Evaluate impurity after threshold split\n",
        "\n",
        "Split rule: go left if X[:,j] <= t else right.\n",
        "Return weighted impurity and information gain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2NpJ4-PuHCH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ba8eda-bd7a-4da9-90f8-39695f5c5cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: gain_positive\n"
          ]
        }
      ],
      "source": [
        "def split_indices(X, j, t):\n",
        "    left = np.where(X[:, j] <= t)[0]\n",
        "    right = np.where(X[:, j] > t)[0]\n",
        "    return left, right\n",
        "\n",
        "def info_gain(y, y_left, y_right, criterion='gini'):\n",
        "    # TODO\n",
        "    f = gini if criterion == 'gini' else entropy\n",
        "    entropy_root = f(y)\n",
        "    entropy_right = f(y_right) * y_right.shape[0]/y.shape[0]\n",
        "    entropy_left = f(y_left) * y_left.shape[0] / y.shape[0]\n",
        "    return (entropy_root - (entropy_left   + entropy_right ))\n",
        "\n",
        "# quick sanity\n",
        "y0 = np.array([0,0,1,1])\n",
        "gain = info_gain(y0, np.array([0,0]), np.array([1,1]), criterion='gini')\n",
        "check('gain_positive', gain > 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCdbfrofHCH5"
      },
      "source": [
        "### Task 2.2: Find best (feature, threshold)\n",
        "\n",
        "# TODO: implement best_split(X, y)\n",
        "# HINT: thresholds from sorted unique feature values midpoints\n",
        "\n",
        "**FAANG gotcha:** if a split makes an empty child, skip it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "LC_RQTB0HCH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b74d2fc6-af90-4a7a-9d06-91e5073cf8ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.35367329 0.35121978]\n",
            "best 0 1.026601307828603 0.033781551081971284\n",
            "best 1 -0.027468770822512693 0.0052853218210361375\n",
            "OK: gain_nonneg\n"
          ]
        }
      ],
      "source": [
        "def best_split(X, y, criterion='gini'):\n",
        "    # TODO: return (best_j, best_t, best_gain)\n",
        "    best_gain = -1000\n",
        "    best_gain_pos = None\n",
        "    best_threshold = None\n",
        "\n",
        "    for feature in range(X.shape[1]):\n",
        "      vals = np.unique(X[:,feature])\n",
        "\n",
        "      if vals.size < 2 :\n",
        "        continue\n",
        "\n",
        "      thresholds = (vals[:-1] + vals[1:]) /2\n",
        "\n",
        "      for threshold in thresholds:\n",
        "        y_left_idx, y_right_idx = split_indices(X, feature, threshold)\n",
        "        if not (np.any(y_left_idx) and np.any(y_right_idx)) :\n",
        "          continue\n",
        "\n",
        "        gain = info_gain(y, y[y_left_idx], y[y_right_idx], criterion=criterion)\n",
        "\n",
        "        if gain > best_gain :\n",
        "          best_gain = gain\n",
        "          best_gain_pos = feature\n",
        "          best_threshold = threshold\n",
        "\n",
        "    return best_gain_pos, best_threshold, best_gain\n",
        "\n",
        "def best_split_no_loop(X, y, criterion='gini'):\n",
        "    left_indices = X <= np.mean(X,axis=0, keepdims=True)\n",
        "    left_y = y[:,None] * left_indices\n",
        "    right_y = y[:,None] * (~left_indices)\n",
        "\n",
        "    left_counts = left_indices.sum(axis=0)\n",
        "    right_counts = X.shape[0] - left_counts\n",
        "\n",
        "    left_p = np.sum(left_y, axis=0)/np.maximum(left_counts,1)\n",
        "    right_p = np.sum(right_y, axis=0)/np.maximum(right_counts,1)\n",
        "    parent_p = y.mean()\n",
        "\n",
        "    left_impurity = (1 - (left_p * left_p + (1-left_p) * (1-left_p))) * (left_counts /X.shape[0])\n",
        "    right_impurity = (1 - (right_p * right_p + (1-right_p) * (1-right_p))) * (right_counts / X.shape[0])\n",
        "    parent_impurity = 1 -  (parent_p * parent_p + (1-parent_p) * (1-parent_p))\n",
        "\n",
        "    total = left_impurity + right_impurity\n",
        "    best_gain_pos = np.argmin(total)\n",
        "    best_threshold = X[:,best_gain_pos].mean()\n",
        "\n",
        "    print (total)\n",
        "    best_gain = parent_impurity - total[best_gain_pos]\n",
        "\n",
        "    return best_gain_pos, best_threshold, best_gain\n",
        "\n",
        "for entropy_fn in ['gini']:\n",
        "  j, t, gain = best_split(Xtr, ytr, entropy_fn)\n",
        "\n",
        "  j_2, t_2, gain_2 = best_split_no_loop(Xtr, ytr, entropy_fn)\n",
        "  print('best', j, t, gain)\n",
        "  print('best', j_2, t_2, gain_2)\n",
        "  check('gain_nonneg', gain >= 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b83KT7BzHCH5"
      },
      "source": [
        "### Task 2.3: Train a stump and evaluate\n",
        "\n",
        "Use best_split to build a stump that predicts majority class on each side.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "xp1bAOPTHCH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b9c406-7866-45b2-d4ac-daf73c33415b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stump train acc 0.7678571428571429\n",
            "stump val acc 0.75\n"
          ]
        }
      ],
      "source": [
        "def stump_predict(X_train, y_train, X_test, criterion='gini'):\n",
        "    best_gain_pos , best_t, best_g = best_split(X_train,  y_train, criterion)\n",
        "    mask = X_train[:, best_gain_pos] <= best_t\n",
        "\n",
        "    values, counts = np.unique(y_train[mask], return_counts=True)\n",
        "    left_class = values[np.argmax(counts)]\n",
        "    values, counts = np.unique(y_train[~mask], return_counts=True)\n",
        "    right_class = values[np.argmax(counts)]\n",
        "    return np.where(X_test[:,best_gain_pos] <= best_t,left_class, right_class)\n",
        "\n",
        "def accuracy(y, yhat):\n",
        "    return float(np.mean(y == yhat))\n",
        "\n",
        "yhat_tr = stump_predict(Xtr, ytr, Xtr)\n",
        "yhat_va = stump_predict(Xtr, ytr, Xva)\n",
        "print('stump train acc', accuracy(ytr, yhat_tr))\n",
        "print('stump val acc', accuracy(yva, yhat_va))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts72cmHuHCH5"
      },
      "source": [
        "## Section 3 — sklearn DecisionTreeClassifier (sanity check)\n",
        "\n",
        "### Task 3.1: Train trees with different max_depth\n",
        "\n",
        "# TODO: train sklearn tree and compare train/val accuracy for depth in [1,2,3,5,None].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "zdFroR_bHCH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29353956-e80f-4ba3-af9a-250f25a62216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_depth 1 train 0.7678571428571429 val 0.75\n",
            "max_depth 2 train 0.7678571428571429 val 0.75\n",
            "max_depth 3 train 0.8428571428571429 val 0.7666666666666667\n",
            "max_depth 5 train 0.9642857142857143 val 0.8416666666666667\n",
            "max_depth None train 1.0 val 0.825\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "depths = [1,2,3,5,None]\n",
        "for md in depths:\n",
        "    clf = DecisionTreeClassifier(max_depth=md, random_state=0)\n",
        "    clf.fit(Xtr, ytr)\n",
        "    tr_acc = clf.score(Xtr, ytr)\n",
        "    va_acc = clf.score(Xva, yva)\n",
        "    print('max_depth', md, 'train', tr_acc, 'val', va_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAN_9C8EHCH6"
      },
      "source": [
        "## Section 4 — Failure mode: leakage\n",
        "\n",
        "### Task 4.1: Create a leaky feature\n",
        "Add a feature that is directly derived from y and watch validation accuracy jump.\n",
        "\n",
        "**Explain:** why do trees exploit leakage aggressively?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wb316BCsHCH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0a472b-9268-4959-8d7d-ebb8dd815c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val acc with leakage 1.0\n"
          ]
        }
      ],
      "source": [
        "Xtr_leak = np.hstack([Xtr, ytr.reshape(-1,1)])\n",
        "Xva_leak = np.hstack([Xva, yva.reshape(-1,1)])\n",
        "\n",
        "clf = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
        "clf.fit(Xtr_leak, ytr)\n",
        "print('val acc with leakage', clf.score(Xva_leak, yva))\n",
        "\n",
        "# Leaked features has the highest entropy drop as they easily classify the target value and hence trees exploit them aggresively"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq9NuUzaHCH6"
      },
      "source": [
        "---\n",
        "## Submission Checklist\n",
        "- All TODOs completed\n",
        "- Stump implemented\n",
        "- sklearn depth sweep shown\n",
        "- Leakage demo explained\n"
      ]
    }
  ]
}